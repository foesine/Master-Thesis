{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baysian Networks\n",
    "with R kernel\n",
    "\n",
    "\n",
    "Bnlearn Tutorial: https://jacintoarias.github.io/bayesnetRtutorial/#the_bnlearn_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lade n\"otiges Paket: synthpop\n",
      "\n",
      "Find out more at https://www.synthpop.org.uk/\n",
      "\n",
      "Lade n\"otiges Paket: insight\n",
      "\n",
      "Lade n\"otiges Paket: party\n",
      "\n",
      "Lade n\"otiges Paket: grid\n",
      "\n",
      "Lade n\"otiges Paket: mvtnorm\n",
      "\n",
      "Lade n\"otiges Paket: modeltools\n",
      "\n",
      "Lade n\"otiges Paket: stats4\n",
      "\n",
      "Lade n\"otiges Paket: strucchange\n",
      "\n",
      "Lade n\"otiges Paket: zoo\n",
      "\n",
      "\n",
      "Attache Paket: 'zoo'\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: sandwich\n",
      "\n",
      "Lade n\"otiges Paket: dplyr\n",
      "\n",
      "\n",
      "Attache Paket: 'dplyr'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:party':\n",
      "\n",
      "    where\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: rpart\n",
      "\n",
      "Lade n\"otiges Paket: rpart.plot\n",
      "\n",
      "Lade n\"otiges Paket: randomForest\n",
      "\n",
      "randomForest 4.7-1.1\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attache Paket: 'randomForest'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: pROC\n",
      "\n",
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "\n",
      "Attache Paket: 'pROC'\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: caret\n",
      "\n",
      "Lade n\"otiges Paket: ggplot2\n",
      "\n",
      "\n",
      "Attache Paket: 'ggplot2'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:randomForest':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: lattice\n",
      "\n",
      "Lade n\"otiges Paket: pracma\n",
      "\n",
      "Lade n\"otiges Paket: bnlearn\n",
      "\n",
      "\n",
      "Attache Paket: 'bnlearn'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:synthpop':\n",
      "\n",
      "    compare\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: arulesCBA\n",
      "\n",
      "Lade n\"otiges Paket: Matrix\n",
      "\n",
      "\n",
      "Attache Paket: 'Matrix'\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:pracma':\n",
      "\n",
      "    expm, lu, tril, triu\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: arules\n",
      "\n",
      "\n",
      "Attache Paket: 'arules'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:bnlearn':\n",
      "\n",
      "    discretize\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:pracma':\n",
      "\n",
      "    size\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:dplyr':\n",
      "\n",
      "    recode\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:modeltools':\n",
      "\n",
      "    info\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:base':\n",
      "\n",
      "    abbreviate, write\n",
      "\n",
      "\n",
      "\n",
      "Attache Paket: 'arulesCBA'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:party':\n",
      "\n",
      "    response\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "9. TRUE\n",
       "10. TRUE\n",
       "11. TRUE\n",
       "12. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] TRUE\n",
       "\n",
       "[[5]]\n",
       "[1] TRUE\n",
       "\n",
       "[[6]]\n",
       "[1] TRUE\n",
       "\n",
       "[[7]]\n",
       "[1] TRUE\n",
       "\n",
       "[[8]]\n",
       "[1] TRUE\n",
       "\n",
       "[[9]]\n",
       "[1] TRUE\n",
       "\n",
       "[[10]]\n",
       "[1] TRUE\n",
       "\n",
       "[[11]]\n",
       "[1] TRUE\n",
       "\n",
       "[[12]]\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_packages <- c (\"synthpop\", \"insight\", \"party\", \"dplyr\", \"rpart\", \"rpart.plot\", \"randomForest\", \"pROC\", \"caret\", \"pracma\", \"bnlearn\", \"arulesCBA\")\n",
    "\n",
    "lapply(list_of_packages, FUN= function(X){\n",
    "  do.call(\"require\", list(X))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "directory <- \"/Users/emmafoessing/Documents/Master/MA/Code/Master-Thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(paste0(directory,\"/cpspop.RData\"))\n",
    "adult <- read.csv(paste0(directory, \"/adult_preprocessed.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# delete NAs\n",
    "adult[adult == \"?\"] <- NA\n",
    "adult <- na.omit(adult)\n",
    "\n",
    "adult$workclass <- as.factor(adult$workclass)\n",
    "adult$education <- as.factor(adult$education)\n",
    "adult$marital_status <- as.factor(adult$marital_status)\n",
    "adult$relationship <- as.factor(adult$relationship)\n",
    "adult$race <- as.factor(adult$race)\n",
    "adult$sex <- as.factor(adult$sex)\n",
    "adult$native_country <- as.factor(adult$native_country)\n",
    "adult$income <- as.factor(adult$income)\n",
    "\n",
    "adult_with_cont <- adult\n",
    "cps_with_cont <- cpspop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich diskretisiere alle meine continuous cars (in Intervalle einteilen) --> das geht mit der discretize function <br>\n",
    "Ich will ca. 5 Kategorien maximal pro Variable haben. Wenn eine der Ausprägungen in der Varibale mindestens 1/5 aller Ausprägungnen aus macht, dann soll diese eine eigene Kategorie werden und die restlichen als Interval kategorisiert werden. Wenn es mehrere Werte gibt, die mindestens 1/5 aller Ausprägungen ausmachen, dann sollen auch diese alle jeweils eine eigene Kategorie werden und der Rest kann in Intervalle eingeteilt werden. Am Ende soll die Variable des Datensatzes überschrieben werden mit der kategorialen Variable und der Datensatz nur aus 'factor' Variablen bestehen.\n",
    "2/5 sind =0 --> 3 weitere Kategorien mit Intervallen\n",
    "3/5 sind =0 --> 2 weitere Kategorien mit Intervallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "discretize_df = function(df, breaks = 5) {\n",
    "  for (var in colnames(df)) {\n",
    "    # Check if the variable is not a factor\n",
    "    if (!is.factor(df[[var]])) {\n",
    "\n",
    "      # Count the frequency of each unique value\n",
    "      freq_table <- table(df[[var]])\n",
    "\n",
    "      # Calculate the proportion of zeros, ensuring NA is handled\n",
    "      zero_proportion <- ifelse(!is.na(freq_table[as.character(0)]), \n",
    "                                freq_table[as.character(0)] / sum(freq_table), \n",
    "                                0)\n",
    "\n",
    "      # Determine the number of breaks based on zero proportion\n",
    "      if (zero_proportion > 4/5) {\n",
    "        new_breaks = 1\n",
    "      } else if (zero_proportion > 1/4) {\n",
    "        new_breaks = breaks - 2\n",
    "      } else if (zero_proportion > 1/5) {\n",
    "        new_breaks = breaks - 1\n",
    "      } else {\n",
    "        new_breaks = breaks\n",
    "      }\n",
    "      \n",
    "      # Separate zeros and non-zeros\n",
    "      zero_portion = (df[[var]] == 0)\n",
    "      non_zero_values = df[[var]][!zero_portion]\n",
    "\n",
    "      # Discretize non-zero values\n",
    "      if (length(non_zero_values) > 0) {\n",
    "        # Calculate breaks for non-zero values\n",
    "        range_values = range(non_zero_values, na.rm = TRUE)\n",
    "        breaks_values = seq(range_values[1], range_values[2], length.out = new_breaks + 1)\n",
    "        \n",
    "        # Ensure correct number of labels are created\n",
    "        labels = sapply(1:(length(breaks_values)-1), function(i) \n",
    "                        paste(\"(\", breaks_values[i], \"-\", breaks_values[i+1], \"]\", sep=\"\"))\n",
    "\n",
    "        # Use cut to apply these breaks and labels\n",
    "        discretized_non_zeros = cut(non_zero_values, breaks = breaks_values, labels = labels, include.lowest = TRUE)\n",
    "        # Combine zero and discretized non-zeros into the original dataframe\n",
    "        df[[var]] <- factor(ifelse(zero_portion, \"0\", as.character(discretized_non_zeros)))\n",
    "      } else {\n",
    "        # If all values are zero or the number of breaks is zero or negative\n",
    "        df[[var]] <- factor(\"0\")\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'(1-23917]'</li><li>'0'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '(1-23917{]}'\n",
       "\\item '0'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '(1-23917]'\n",
       "2. '0'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"(1-23917]\" \"0\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cps_dis <- discretize_df(cpspop)\n",
    "levels(cps_dis$csp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Using a Baysian Network to generate synthetic data\n",
    "baysian_net <- function(data){\n",
    "    # discretize data before creating syn. data\n",
    "    #data <- discretize_df(data)\n",
    "    bn <- hc(data)  # Learn structure using Hill-Climbing\n",
    "    bn <- bn.fit(bn, data)  # Learn parameters using Maximum Likelihood Estimation\n",
    "\n",
    "    # Generate Synthetic Data\n",
    "    syn_data <- rbn(bn, length(data))  # Generate same number of obs as in the original data\n",
    "\n",
    "    return(syn_data)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Problem: Baysian networks require data structure with solely discrete variables!\n",
    "--> exists in both CPS and Adult\n",
    "For continuous data, common practice would be to first discretize the variables (convert the continuous data into bins or categories) and then apply Bayesian Network algorithms. However, the process of discretization must be done very thoughtfully as ill-advised discretization can lead to loss of crucial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "adult_syn <- baysian_net(discretize_df(adult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cps_syn <- baysian_net(discretize_df(cps_with_cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 x 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>tax</th><th scope=col>income</th><th scope=col>csp</th><th scope=col>age</th><th scope=col>educ</th><th scope=col>marital</th><th scope=col>race</th><th scope=col>sex</th><th scope=col>ss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>(1-33333]</td><td>(1-153749.2]</td><td>0</td><td>(30-45]</td><td>39</td><td>1</td><td>1</td><td>1</td><td>0                   </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>(1-33333]</td><td>(1-153749.2]</td><td>0</td><td>(60-75]</td><td>46</td><td>1</td><td>1</td><td>1</td><td>(7-16671.3333333333]</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>(1-33333]</td><td>(1-153749.2]</td><td>0</td><td>(45-60]</td><td>39</td><td>1</td><td>1</td><td>1</td><td>0                   </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>(1-33333]</td><td>(1-153749.2]</td><td>0</td><td>(60-75]</td><td>39</td><td>4</td><td>1</td><td>2</td><td>(7-16671.3333333333]</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>(1-33333]</td><td>(1-153749.2]</td><td>0</td><td>(30-45]</td><td>40</td><td>1</td><td>1</td><td>1</td><td>0                   </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>(1-33333]</td><td>(1-153749.2]</td><td>0</td><td>(60-75]</td><td>39</td><td>1</td><td>1</td><td>1</td><td>0                   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 x 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & tax & income & csp & age & educ & marital & race & sex & ss\\\\\n",
       "  & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & (1-33333{]} & (1-153749.2{]} & 0 & (30-45{]} & 39 & 1 & 1 & 1 & 0                   \\\\\n",
       "\t2 & (1-33333{]} & (1-153749.2{]} & 0 & (60-75{]} & 46 & 1 & 1 & 1 & (7-16671.3333333333{]}\\\\\n",
       "\t3 & (1-33333{]} & (1-153749.2{]} & 0 & (45-60{]} & 39 & 1 & 1 & 1 & 0                   \\\\\n",
       "\t4 & (1-33333{]} & (1-153749.2{]} & 0 & (60-75{]} & 39 & 4 & 1 & 2 & (7-16671.3333333333{]}\\\\\n",
       "\t5 & (1-33333{]} & (1-153749.2{]} & 0 & (30-45{]} & 40 & 1 & 1 & 1 & 0                   \\\\\n",
       "\t6 & (1-33333{]} & (1-153749.2{]} & 0 & (60-75{]} & 39 & 1 & 1 & 1 & 0                   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 x 9\n",
       "\n",
       "| <!--/--> | tax &lt;fct&gt; | income &lt;fct&gt; | csp &lt;fct&gt; | age &lt;fct&gt; | educ &lt;fct&gt; | marital &lt;fct&gt; | race &lt;fct&gt; | sex &lt;fct&gt; | ss &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | (1-33333] | (1-153749.2] | 0 | (30-45] | 39 | 1 | 1 | 1 | 0                    |\n",
       "| 2 | (1-33333] | (1-153749.2] | 0 | (60-75] | 46 | 1 | 1 | 1 | (7-16671.3333333333] |\n",
       "| 3 | (1-33333] | (1-153749.2] | 0 | (45-60] | 39 | 1 | 1 | 1 | 0                    |\n",
       "| 4 | (1-33333] | (1-153749.2] | 0 | (60-75] | 39 | 4 | 1 | 2 | (7-16671.3333333333] |\n",
       "| 5 | (1-33333] | (1-153749.2] | 0 | (30-45] | 40 | 1 | 1 | 1 | 0                    |\n",
       "| 6 | (1-33333] | (1-153749.2] | 0 | (60-75] | 39 | 1 | 1 | 1 | 0                    |\n",
       "\n"
      ],
      "text/plain": [
       "  tax       income       csp age     educ marital race sex ss                  \n",
       "1 (1-33333] (1-153749.2] 0   (30-45] 39   1       1    1   0                   \n",
       "2 (1-33333] (1-153749.2] 0   (60-75] 46   1       1    1   (7-16671.3333333333]\n",
       "3 (1-33333] (1-153749.2] 0   (45-60] 39   1       1    1   0                   \n",
       "4 (1-33333] (1-153749.2] 0   (60-75] 39   4       1    2   (7-16671.3333333333]\n",
       "5 (1-33333] (1-153749.2] 0   (30-45] 40   1       1    1   0                   \n",
       "6 (1-33333] (1-153749.2] 0   (60-75] 39   1       1    1   0                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(cps_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "für die Simulation:\n",
    "Predictions mit dem kategorisiertem Datensatz? Ergibt nur Sinn weil sonst sind die Bedingungen ganz verschiedene.\n",
    "Aber: Wenn ich BN auch mit reinnehme als Modelle für die Predictions bei den anderen SDGs dann hat die Performance es schlechter --> überhaupt vergleichbar mit anderen Modellen? (letztendlich muss nur synthetisch gegen original verglichen werden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to perform the structure learning and fitting\n",
    "train_bn <- function(data, algorithm, score) {\n",
    "  if (algorithm == \"hc\") {\n",
    "    bn_structure <- hc(data, score = score)\n",
    "  } else if (algorithm == \"tabu\") {\n",
    "    bn_structure <- tabu(data, score = score)\n",
    "  } else if (algorithm == \"gs\") {\n",
    "    bn_structure <- gs(data)\n",
    "  } else if (algorithm == \"iamb\") {\n",
    "    bn_structure <- iamb(data)\n",
    "  }\n",
    "  \n",
    "  bn_fitted <- bn.fit(bn_structure, data)\n",
    "  return(bn_fitted)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to evaluate the model using cross-validation\n",
    "evaluate_bn <- function(data, bn_fitted, target_var) {\n",
    "  predictions <- predict(bn_fitted, data = data, node = target_var)\n",
    "  actual <- data[[target_var]]\n",
    "  accuracy <- mean(predictions == actual)\n",
    "  return(accuracy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for factored targets\n",
    "evaluation_metrics_factor <- function(predictions, test_set){\n",
    "    # confusion matrix for the prediction on original data\n",
    "    cm <- confusionMatrix(predictions, test_set$income,\n",
    "                mode = \"everything\")\n",
    "\n",
    "    # saving evaluation metrics\n",
    "    accuracy <- cm$overall['Accuracy']\n",
    "    f1 <- cm$byClass['F1']\n",
    "    sens <- cm$byClass['Sensitivity']\n",
    "    spec <- cm$byClass['Specificity']\n",
    "\n",
    "    # Create the dataframe\n",
    "    metrics_df <- data.frame(\n",
    "        Accuracy = accuracy, \n",
    "        F1 = f1, \n",
    "        Sensitivity = sens, \n",
    "        Specificity = spec\n",
    "    )\n",
    "    \n",
    "    return(metrics_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bn_simulation <- function(data, nrun = 10, kfold = 10, algorithms = c(\"hc\", \"tabu\", \"gs\", \"iamb\"), scores = c(\"aic\", \"bic\", \"k2\")) {\n",
    "\n",
    "    # create empty list to store evaluation dataframes\n",
    "    eval_list <- list()\n",
    "\n",
    "    # discretize the data\n",
    "    data <- discretize_df(data)\n",
    "\n",
    "    # set inital seed\n",
    "    s <- 1234\n",
    "    for (i in 1:nrun){\n",
    "        # vary seed with each run\n",
    "        s <- s + 1\n",
    "        set.seed(s)\n",
    "\n",
    "        # generate synthetic data\n",
    "        gen_data <- baysian_net(data)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        trainIndex <- createDataPartition(data$income, p = .8, \n",
    "                                            list = FALSE, \n",
    "                                            times = 1)\n",
    "        trainData <- data[ trainIndex,]\n",
    "        testData  <- data[-trainIndex,]\n",
    "        \n",
    "        # define control for CV\n",
    "        control <- trainControl(method = \"cv\", number = kfold)\n",
    "\n",
    "        train_control <- trainControl(method = \"cv\", number = 5)\n",
    "\n",
    "        # Define the grid of parameters\n",
    "        grid <- expand.grid(algorithm = algorithms, score = scores)\n",
    "        \n",
    "        # Define the target variable\n",
    "        target_var <- \"income\"\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        results <- lapply(1:nrow(grid), function(i) {\n",
    "            algorithm <- grid$algorithm[i]\n",
    "            score <- ifelse(grid$algorithm[i] %in% c(\"hc\", \"tabu\"), grid$score[i], NA)\n",
    "            \n",
    "            bn_fitted <- train_bn(data, algorithm, score)\n",
    "            accuracy <- evaluate_bn(data, bn_fitted, target_var)\n",
    "            \n",
    "            return(data.frame(algorithm = algorithm, score = score, accuracy = accuracy))\n",
    "        })\n",
    "\n",
    "        # Combine results into a single data frame\n",
    "        results <- do.call(rbind, results)\n",
    "\n",
    "        # Select the best model\n",
    "        best_model <- results[which.max(results$accuracy),]\n",
    "\n",
    "        # Train the best model on the entire dataset\n",
    "        final_bn <- train_bn(trainData, best_model$algorithm, best_model$score)\n",
    "        \n",
    "        # Use the final model for prediction\n",
    "        predictions <- predict(final_bn, data = testData, node = target_var)\n",
    "\n",
    "        # Evaluate the final model\n",
    "        eval <- as.data.frame(evaluation_metrics_factor(predictions, testData))\n",
    "\n",
    "        eval_list[[i]] <- eval\n",
    "        print(c(\"run\", i, \"completed\"))\n",
    "    }\n",
    "\n",
    "    # outside the nruns loop\n",
    "    # average over all runs\n",
    "    sum_df <- Reduce(function(x, y) Map(`+`, x, y), eval_list)\n",
    "    eval_avg <- lapply(sum_df, function(col) col / length(eval_list))\n",
    "\n",
    "    # Convert the list back to a dataframe\n",
    "    # Store row names\n",
    "    rownames <- row.names(eval_list[[1]])\n",
    "\n",
    "    # Convert the list back to a dataframe\n",
    "    eval_avg <- as.data.frame(eval_avg)\n",
    "\n",
    "    # Set back the row names\n",
    "    rownames(eval_avg) <- row.names(eval_list[[1]])\n",
    "\n",
    "    # Return the average evaluation metrics\n",
    "    return(eval_avg)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Percepron\n",
    "with R kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die heruntergeladenen Bin\"arpakete sind in \n",
      "\t/var/folders/kj/dkjqkk2n3wq2zfbttgdpjrj80000gn/T//Rtmpjw3DfT/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lade n\"otiges Paket: tensorflow\n",
      "\n",
      "Warning message:\n",
      "\"Paket 'tensorflow' wurde unter R Version 4.3.2 erstellt\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attache Paket: 'tensorflow'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:caret':\n",
      "\n",
      "    train\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: keras\n",
      "\n",
      "Warning message:\n",
      "\"Paket 'keras' wurde unter R Version 4.3.2 erstellt\"\n",
      "\n",
      "Attache Paket: 'keras'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:party':\n",
      "\n",
      "    fit\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:modeltools':\n",
      "\n",
      "    fit\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:insight':\n",
      "\n",
      "    get_weights\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "9. TRUE\n",
       "10. TRUE\n",
       "11. TRUE\n",
       "12. TRUE\n",
       "13. TRUE\n",
       "14. TRUE\n",
       "15. TRUE\n",
       "16. TRUE\n",
       "17. TRUE\n",
       "18. TRUE\n",
       "19. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] TRUE\n",
       "\n",
       "[[5]]\n",
       "[1] TRUE\n",
       "\n",
       "[[6]]\n",
       "[1] TRUE\n",
       "\n",
       "[[7]]\n",
       "[1] TRUE\n",
       "\n",
       "[[8]]\n",
       "[1] TRUE\n",
       "\n",
       "[[9]]\n",
       "[1] TRUE\n",
       "\n",
       "[[10]]\n",
       "[1] TRUE\n",
       "\n",
       "[[11]]\n",
       "[1] TRUE\n",
       "\n",
       "[[12]]\n",
       "[1] TRUE\n",
       "\n",
       "[[13]]\n",
       "[1] TRUE\n",
       "\n",
       "[[14]]\n",
       "[1] TRUE\n",
       "\n",
       "[[15]]\n",
       "[1] TRUE\n",
       "\n",
       "[[16]]\n",
       "[1] TRUE\n",
       "\n",
       "[[17]]\n",
       "[1] TRUE\n",
       "\n",
       "[[18]]\n",
       "[1] TRUE\n",
       "\n",
       "[[19]]\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_packages <- c (\"synthpop\", \"insight\", \"party\", \"dplyr\", \"rpart\", \"rpart.plot\", \"randomForest\", \"pROC\", \"caret\", \"pracma\", \"here\", \"Hmisc\", \"arf\", \"randomForest\", \"caret\", \"xgboost\", \"data.table\", \"tensorflow\",\"keras\")\n",
    "\n",
    "lapply(list_of_packages, FUN= function(X){\n",
    "  do.call(\"require\", list(X))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(file = (paste0(here(), \"/cpspop.RData\")))\n",
    "adult <- read.csv(file = (paste0(here(),\"/adult_preprocessed.csv\")))\n",
    "# delete NAs\n",
    "adult[adult == \"?\"] <- NA\n",
    "adult <- na.omit(adult)\n",
    "\n",
    "adult$workclass <- as.factor(adult$workclass)\n",
    "adult$education <- as.factor(adult$education)\n",
    "adult$marital_status <- as.factor(adult$marital_status)\n",
    "adult$relationship <- as.factor(adult$relationship)\n",
    "adult$race <- as.factor(adult$race)\n",
    "adult$sex <- as.factor(adult$sex)\n",
    "adult$native_country <- as.factor(adult$native_country)\n",
    "adult$income <- as.factor(adult$income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out the MLP\n",
    "1. Prepare Data: Split your data into features and target. Normalize the features to ensure better performance of the neural network. <br>\n",
    "2. Define and Train the MLP Model: Define the architecture of the MLP, compile the model, and train it on your data. <br>\n",
    "3. Generate Synthetic Data: Sample from the feature space, use the trained model to predict the target variable for these samples, and combine the predictions with the sampled features to create synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# convert all variables in df to numeric\n",
    "convert_to_numeric <- function(df) {\n",
    "  # Convert factors to numeric\n",
    "  df[] <- lapply(df, function(col) {\n",
    "    if (is.factor(col)) {\n",
    "      return(as.numeric(col))\n",
    "    } else {\n",
    "      return(col)\n",
    "    }\n",
    "})\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Identify features and target\n",
    "data <- adult\n",
    "\n",
    "data <- convert_to_numeric(data)\n",
    "target_col <- 'income'\n",
    "features <- setdiff(names(data), target_col)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X <- data[, features]\n",
    "y <- data[, target_col]\n",
    "\n",
    "X_means <- colMeans(X)\n",
    "X_sds <- apply(X, 2, sd)\n",
    "\n",
    "# Normalize features\n",
    "X_normalized <- scale(X, center = X_means, scale = X_sds)\n",
    "\n",
    "# Store the mean and standard deviation of the target\n",
    "y_mean <- mean(y)\n",
    "y_sd <- sd(y)\n",
    "\n",
    "# Normalize target\n",
    "y_normalized <- scale(y, center = y_mean, scale = y_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define the MLP model\n",
    "model <- keras_model_sequential() %>%\n",
    "  layer_dense(units = 64, activation = 'relu', input_shape = ncol(X)) %>%\n",
    "  layer_dense(units = 32, activation = 'relu') %>%\n",
    "  layer_dense(units = 1)  # Single output for regression\n",
    "\n",
    "# Compile the model\n",
    "model %>% compile(\n",
    "  loss = 'mean_squared_error',\n",
    "  optimizer = optimizer_adam(),\n",
    "  metrics = c('mean_absolute_error')\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history <- model %>% fit(\n",
    "  as.matrix(X), y,\n",
    "  epochs = 100,\n",
    "  batch_size = 32,\n",
    "  validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "generate_synthetic_data <- function(model, X, X_means, X_sds, y_mean, y_sd, n_samples) {\n",
    "  synthetic_data <- list()\n",
    "  for (i in 1:n_samples) {\n",
    "    # Sample a random row from the normalized feature matrix\n",
    "    random_sample <- X[sample(1:nrow(X), 1), , drop = FALSE]\n",
    "    \n",
    "    # Predict the normalized target variable for the sampled row\n",
    "    prediction <- model %>% predict(as.matrix(random_sample))\n",
    "    \n",
    "    # Denormalize the predicted target\n",
    "    prediction_denormalized <- prediction * y_sd + y_mean\n",
    "    \n",
    "    # Combine the random sample with the denormalized predicted target\n",
    "    synthetic_sample <- as.data.frame(random_sample)\n",
    "    synthetic_sample$income <- prediction_denormalized\n",
    "    \n",
    "    # Denormalize the features\n",
    "    denormalized_sample <- synthetic_sample\n",
    "    for (col in names(synthetic_sample)[-ncol(synthetic_sample)]) {\n",
    "      denormalized_sample[[col]] <- synthetic_sample[[col]] * X_sds[col] + X_means[col]\n",
    "    }\n",
    "    \n",
    "    # Append to the list\n",
    "    synthetic_data[[i]] <- denormalized_sample\n",
    "  }\n",
    "  \n",
    "  # Combine all synthetic samples into a data frame\n",
    "  synthetic_df <- do.call(rbind, synthetic_data)\n",
    "  return(synthetic_df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age workclass fnlwgt education marital_status occupation relationship\n",
      "8343   44         3 193494        16              3         13            1\n",
      "3701   39         3 328466         2              3          7            1\n",
      "17407  21         3 186314        12              3          0            1\n",
      "23435  35         5 114366        10              3          9            1\n",
      "11688  41         3 277192         5              3          4            6\n",
      "29080  31         3  73585         9              3          9            1\n",
      "      race sex capital_gain capital_loss hours_per_week native_country   income\n",
      "8343     5   2            0            0             72             39 1.137240\n",
      "3701     5   2         2407            0             70             26 1.173232\n",
      "17407    5   2            0            0             40             39 1.257761\n",
      "23435    5   2            0            0             40             39 1.196040\n",
      "11688    5   1            0            0             40             26 1.172184\n",
      "29080    5   2            0            0             45             39 1.227194\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data <- generate_synthetic_data(model, X_normalized, X_means, X_sds, y_mean, y_sd, 1000)  # Generate 1000 synthetic samples\n",
    "\n",
    "print(head(synthetic_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set the library path\n",
    "#.libPaths(\"/user/emma.foessing01/u11969/new_R_libs\")\n",
    "Sys.setenv(\"PKG_CXXFLAGS\"=\"-std=c++14\")\n",
    "\n",
    "print(R.version.string)\n",
    "\n",
    "# List of required packages\n",
    "list_of_packages <- c(\n",
    "  \"synthpop\", \"jsonlite\", \"codetools\", \"insight\", \"party\", \"haven\", \"dplyr\", \"rpart\", \"rpart.plot\",\n",
    "  \"randomForest\", \"pROC\", \"caret\", \"pracma\", \"here\", \"Hmisc\", \"purrr\",\n",
    "  \"ranger\", \"bnlearn\", \"arulesCBA\", \"network\", \"igraph\", \"xgboost\",\n",
    "  \"data.table\", \"doParallel\", \"parallel\", \"ExtDist\", \"e1071\"\n",
    ")\n",
    "\n",
    "# Function to load packages and handle errors\n",
    "load_if_installed <- function(p) {\n",
    "  tryCatch({\n",
    "    library(p, character.only = TRUE)\n",
    "  }, error = function(e) {\n",
    "    message(sprintf(\"Package '%s' is not installed.\", p))\n",
    "  })\n",
    "}\n",
    "\n",
    "# Load all required packages\n",
    "lapply(list_of_packages, load_if_installed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(file = (paste0(here(), \"/cpspop.RData\")))\n",
    "cpspop <- cpspop[, c(setdiff(names(cpspop), c(\"income\", \"race\", \"marital\", \"educ\")), \"income\", \"race\", \"marital\", \"educ\")] #\n",
    "\n",
    "adult <- read.csv(file = (paste0(here(),\"/adult_preprocessed.csv\")))\n",
    "# delete NAs\n",
    "adult[adult == \"?\"] <- NA\n",
    "adult <- na.omit(adult)\n",
    "\n",
    "adult$workclass <- as.factor(adult$workclass)\n",
    "adult$education <- as.factor(adult$education)\n",
    "adult$marital_status <- as.factor(adult$marital_status)\n",
    "adult$relationship <- as.factor(adult$relationship)\n",
    "adult$race <- as.factor(adult$race)\n",
    "adult$sex <- as.factor(adult$sex)\n",
    "adult$native_country <- as.factor(adult$native_country)\n",
    "adult$income <- as.factor(adult$income)\n",
    "adult$occupation <- as.factor(adult$occupation)\n",
    "\n",
    "adult <- adult[, c(\"age\", \"fnlwgt\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"income\", \"sex\", \"race\", \"relationship\", \"marital_status\", \"workclass\", \"occupation\", \"education\", \"native_country\")]\n",
    "adult[] <- lapply(adult, function(col) {\n",
    "  if (is.integer(col)) {\n",
    "    as.numeric(col)\n",
    "  } else {\n",
    "    col\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Datensatz zu genieren (m = 1) ist ausreichend, da ich keine Varianzanalyse machen werde. Damit die Ergebnisse nicht von einem zufälligen Prozess abhängen ist es sinnvoll über ein paar runs Mittelwerte zu bilden (50–100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics for continuous targets\n",
    "evaluation_metrics_cont <- function(predictions, test_set){\n",
    "    # Residuals\n",
    "    residuals <- predictions - test_set$income\n",
    "    \n",
    "    # Mean Absolute Error (MAE)\n",
    "    MAE <- mean(abs(residuals))\n",
    "    \n",
    "    # Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)\n",
    "    MSE <- mean(residuals^2)\n",
    "    RMSE <- sqrt(MSE)\n",
    "    \n",
    "    # R-squared: Guarding against zero variance in the target\n",
    "    SS_res <- sum(residuals^2)\n",
    "    SS_tot <- sum((test_set$income - mean(test_set$income))^2)\n",
    "    R_squared <- ifelse(SS_tot == 0, NA, 1 - (SS_res / SS_tot))\n",
    "    \n",
    "    # Mean Absolute Percentage Error (MAPE): Handling division by zero\n",
    "    MAPE <- ifelse(any(test_set$income == 0), NA, mean(abs(residuals / test_set$income)) * 100)\n",
    "    \n",
    "    metrics_df <- data.frame(\n",
    "        MAE = MAE, \n",
    "        MSE = MSE, \n",
    "        RMSE = RMSE, \n",
    "        R_squared = R_squared, \n",
    "        MAPE = MAPE\n",
    "    )\n",
    "    \n",
    "    return(metrics_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics for factored targets\n",
    "evaluation_metrics_factor <- function(predictions, test_set) {\n",
    "    # Ensure test_set is a data frame\n",
    "    test_set <- as.data.frame(test_set)\n",
    "    \n",
    "    # Ensure both predictions and test_set$income are factors with the same levels\n",
    "    predictions <- as.factor(predictions)\n",
    "    reference <- as.factor(test_set$income)\n",
    "    \n",
    "    # Ensure levels match between predictions and reference\n",
    "    levels(predictions) <- levels(reference)\n",
    "    \n",
    "    # Confusion matrix for the prediction on original data\n",
    "    cm <- caret::confusionMatrix(predictions, reference, mode = \"everything\")\n",
    "\n",
    "    # Saving evaluation metrics\n",
    "    accuracy <- cm$overall['Accuracy']\n",
    "    \n",
    "    if (length(levels(reference)) == 2) {\n",
    "        # Binary classification\n",
    "        f1 <- cm$byClass['F1']\n",
    "        sens <- cm$byClass['Sensitivity']\n",
    "        spec <- cm$byClass['Specificity']\n",
    "    } else {\n",
    "        # Multi-class classification: calculate metrics for each class and take the mean\n",
    "        f1 <- mean(cm$byClass[,'F1'], na.rm = TRUE)\n",
    "        sens <- mean(cm$byClass[,'Sensitivity'], na.rm = TRUE)\n",
    "        spec <- mean(cm$byClass[,'Specificity'], na.rm = TRUE)\n",
    "    }\n",
    "\n",
    "    # Create the dataframe\n",
    "    metrics_df <- data.frame(\n",
    "        Accuracy = accuracy, \n",
    "        F1 = f1, \n",
    "        Sensitivity = sens, \n",
    "        Specificity = spec\n",
    "    )\n",
    "    \n",
    "    return(metrics_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "discretize_df <- function(df, breaks = 5) {\n",
    "  for (var in colnames(df)) {\n",
    "    if (!is.factor(df[[var]])) {\n",
    "      freq_table <- table(df[[var]])\n",
    "      zero_proportion <- ifelse(!is.na(freq_table[as.character(0)]), \n",
    "                                freq_table[as.character(0)] / sum(freq_table), \n",
    "                                0)\n",
    "\n",
    "      new_breaks <- if (zero_proportion > 4/5) 1 else if (zero_proportion > 1/4) breaks - 2 else if (zero_proportion > 1/5) breaks - 1 else breaks\n",
    "      \n",
    "      zero_portion <- (df[[var]] == 0)\n",
    "      non_zero_values <- as.numeric(as.character(df[[var]][!zero_portion]))\n",
    "\n",
    "      if (length(non_zero_values) > 0) {\n",
    "        range_values <- range(non_zero_values)\n",
    "        breaks_values <- seq(range_values[1], range_values[2], length.out = new_breaks + 1)\n",
    "        labels <- paste(\"(\", head(breaks_values, -1), \"-\", tail(breaks_values, -1), \"]\", sep = \"\")\n",
    "\n",
    "        discretized_non_zeros <- cut(non_zero_values, breaks = breaks_values, labels = labels, include.lowest = TRUE)\n",
    "        df[[var]][!zero_portion] <- as.character(discretized_non_zeros)\n",
    "      }\n",
    "      df[[var]][zero_portion] <- \"0\"\n",
    "      df[[var]] <- factor(df[[var]])\n",
    "    }\n",
    "  }\n",
    "  return(df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "inner_cv <- function(data, target_var, folds, algorithms) {\n",
    "  # Create inner folds\n",
    "  inner_folds <- createFolds(data[[target_var]], k = folds)\n",
    "  \n",
    "  best_model <- NULL\n",
    "  best_performance <- -Inf\n",
    "  best_algorithm <- NULL\n",
    "  \n",
    "  for (algorithm in algorithms) {\n",
    "    cat(\"Trying algorithm:\", algorithm, \"\\n\")\n",
    "    fold_results <- c()\n",
    "    \n",
    "    for (i in seq_along(inner_folds)) {\n",
    "      inner_test_index <- inner_folds[[i]]\n",
    "      inner_trainData <- data[-inner_test_index, ]\n",
    "      inner_testData <- data[inner_test_index, ]\n",
    "      \n",
    "      # Fit Bayesian Network model using bnlearn algorithm\n",
    "      bn_model <- do.call(get(algorithm, envir = asNamespace(\"bnlearn\")), list(inner_trainData))\n",
    "      \n",
    "      # Fit the model to the training data\n",
    "      fitted_bn_model <- bnlearn::bn.fit(bn_model, inner_trainData)\n",
    "      \n",
    "      # Use Bayesian Likelihood Weighting for prediction\n",
    "      predictions <- predict(fitted_bn_model, node = target_var, data = inner_testData, method = \"bayes-lw\")\n",
    "      \n",
    "      # Handle missing levels in prediction\n",
    "      predictions <- factor(predictions, levels = levels(inner_trainData[[target_var]]))\n",
    "      \n",
    "      # Calculate the accuracy\n",
    "      accuracy <- mean(predictions == inner_testData[[target_var]], na.rm = TRUE)\n",
    "      fold_results[i] <- accuracy\n",
    "    }\n",
    "    \n",
    "    # Average performance for this algorithm\n",
    "    avg_performance <- mean(fold_results, na.rm = TRUE)\n",
    "    \n",
    "    if (!is.na(avg_performance) && avg_performance > best_performance) {\n",
    "      best_performance <- avg_performance\n",
    "      best_model <- fitted_bn_model\n",
    "      best_algorithm <- algorithm\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  cat(\"Best algorithm selected:\", best_algorithm, \"with accuracy:\", best_performance, \"\\n\")\n",
    "  return(best_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bn_pred <- function(data, outer_folds, inner_folds) {\n",
    "  # Discretize the data\n",
    "  data <- discretize_df(data)\n",
    "  \n",
    "  algorithms <- c(\"tabu\") # without hc\n",
    "  data$income <- factor(data$income, levels = unique(data$income))\n",
    "  \n",
    "  outer_cv_folds <- createFolds(data$income, k = outer_folds)\n",
    "  \n",
    "  # Setup parallel backend\n",
    "  num_cores <- detectCores() - 1  # You can adjust this depending on available cores\n",
    "  cl <- makeCluster(num_cores)\n",
    "  registerDoParallel(cl)\n",
    "  \n",
    "  # Use foreach for parallelization of outer folds\n",
    "  outer_results <- foreach(i = seq_along(outer_cv_folds), \n",
    "                           .packages = c(\"caret\", \"dplyr\", \"bnlearn\", \"doParallel\", \"foreach\", \"parallel\"), \n",
    "                           .export = c(\"discretize_df\", \"inner_cv\", \"evaluation_metrics_factor\")) %dopar% {\n",
    "    outer_test_index <- outer_cv_folds[[i]]\n",
    "    outer_testData <- data[outer_test_index, ]\n",
    "    outer_trainData <- data[-outer_test_index, ]\n",
    "    \n",
    "    # Get the best fitted model from inner CV\n",
    "    best_model <- inner_cv(outer_trainData, \"income\", inner_folds, algorithms)\n",
    "    \n",
    "    # Perform prediction using 'bayes-lw' method\n",
    "    predictions <- predict(best_model, node = \"income\", data = outer_testData, method = \"bayes-lw\")\n",
    "    \n",
    "    # Ensure both predictions and test data are factors\n",
    "    predictions <- factor(predictions, levels = levels(outer_testData$income))\n",
    "    \n",
    "    cat(\"Class of outer_testData: \", class(outer_testData), \"\\n\")\n",
    "\n",
    "    # Evaluate predictions (ensure test data is also a factor)\n",
    "    eval <- evaluation_metrics_factor(predictions, outer_testData)\n",
    "    \n",
    "    return(eval)\n",
    "  }\n",
    "  \n",
    "  stopCluster(cl)  # Stop the cluster when done\n",
    "  registerDoSEQ()\n",
    "\n",
    "  # Average the evaluation metrics over the outer folds\n",
    "  eval_avg_outer_folds <- do.call(rbind, outer_results) %>%\n",
    "                          dplyr::summarise(across(everything(), mean, na.rm = TRUE))\n",
    "  \n",
    "  return(eval_avg_outer_folds)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "s <- 1236\n",
    "set.seed(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "syndata <- readRDS(paste0(here(), \"/results/\", \"cps\", \"_svm_\", as.character(s), \".rds\"))\n",
    "BN_eval <- bn_pred(syndata, outer_folds = 5, inner_folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "BN_eval"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Simulation\n",
    "With R kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die heruntergeladenen Bin\"arpakete sind in \n",
      "\t/var/folders/kj/dkjqkk2n3wq2zfbttgdpjrj80000gn/T//RtmpyMpQOZ/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"arulesCBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lade n\"otiges Paket: synthpop\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find out more at https://www.synthpop.org.uk/\n",
      "\n",
      "Lade n\"otiges Paket: insight\n",
      "\n",
      "Lade n\"otiges Paket: party\n",
      "\n",
      "Lade n\"otiges Paket: grid\n",
      "\n",
      "Lade n\"otiges Paket: mvtnorm\n",
      "\n",
      "Lade n\"otiges Paket: modeltools\n",
      "\n",
      "Lade n\"otiges Paket: stats4\n",
      "\n",
      "Lade n\"otiges Paket: strucchange\n",
      "\n",
      "Lade n\"otiges Paket: zoo\n",
      "\n",
      "\n",
      "Attache Paket: 'zoo'\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: sandwich\n",
      "\n",
      "Lade n\"otiges Paket: dplyr\n",
      "\n",
      "\n",
      "Attache Paket: 'dplyr'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:party':\n",
      "\n",
      "    where\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: rpart\n",
      "\n",
      "Lade n\"otiges Paket: rpart.plot\n",
      "\n",
      "Warning message:\n",
      "\"Paket 'rpart.plot' wurde unter R Version 4.3.2 erstellt\"\n",
      "Lade n\"otiges Paket: randomForest\n",
      "\n",
      "randomForest 4.7-1.1\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attache Paket: 'randomForest'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: pROC\n",
      "\n",
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "\n",
      "Attache Paket: 'pROC'\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: caret\n",
      "\n",
      "Lade n\"otiges Paket: ggplot2\n",
      "\n",
      "\n",
      "Attache Paket: 'ggplot2'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:randomForest':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n",
      "Lade n\"otiges Paket: lattice\n",
      "\n",
      "Lade n\"otiges Paket: pracma\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "9. TRUE\n",
       "10. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] TRUE\n",
       "\n",
       "[[5]]\n",
       "[1] TRUE\n",
       "\n",
       "[[6]]\n",
       "[1] TRUE\n",
       "\n",
       "[[7]]\n",
       "[1] TRUE\n",
       "\n",
       "[[8]]\n",
       "[1] TRUE\n",
       "\n",
       "[[9]]\n",
       "[1] TRUE\n",
       "\n",
       "[[10]]\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_packages <- c (\"synthpop\", \"insight\", \"party\", \"dplyr\", \"rpart\", \"rpart.plot\", \"randomForest\", \"pROC\", \"caret\", \"pracma\")\n",
    "\n",
    "lapply(list_of_packages, FUN= function(X){\n",
    "  do.call(\"require\", list(X))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(\"/Users/emmafoessing/Documents/Master/MA/Synthpop/cpspop.RData\")\n",
    "adult <- read.csv(\"/Users/emmafoessing/Documents/Master/MA/Code/adult_preprocessed.csv\")\n",
    "# delete NAs\n",
    "adult[adult == \"?\"] <- NA\n",
    "adult <- na.omit(adult)\n",
    "\n",
    "adult$workclass <- as.factor(adult$workclass)\n",
    "adult$education <- as.factor(adult$education)\n",
    "adult$marital_status <- as.factor(adult$marital_status)\n",
    "adult$relationship <- as.factor(adult$relationship)\n",
    "adult$race <- as.factor(adult$race)\n",
    "adult$sex <- as.factor(adult$sex)\n",
    "adult$native_country <- as.factor(adult$native_country)\n",
    "adult$income <- as.factor(adult$income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Datensatz zu genieren (m = 1) ist ausreichend, da ich keine Varianzanalyse machen werde. Damit die Ergebnisse nicht von einem zufälligen Prozess abhängen ist es sinnvoll über ein paar runs Mittelwerte zu bilden (50–100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## tree fct with control component\n",
    "\n",
    "build_tree <- function(data,trainsplit = 0.8, cp = 0.01){ #minsplit=20, minbucket=5, maxdepth=20, \n",
    "    train_index <- sample(1:nrow(data), nrow(data)*trainsplit)\n",
    "    # train dataset formation\n",
    "    train_set <- data[train_index, ]\n",
    "    # test dataset formation\n",
    "    test_set <- data[-train_index, ]\n",
    "\n",
    "    tree <- rpart(income ~ ., data = train_set, cp=cp)\n",
    "\n",
    "    # Predict on the test set\n",
    "    predictions <- predict(tree, test_set)#, type = \"prob\")\n",
    "\n",
    "    # for factored variables this will give probabilities, so there is a need to create the actual predictions\n",
    "    if (is.factor(data$income)){\n",
    "        # Initialize predictions as just the probability predictions\n",
    "        predictions_prob <- predictions\n",
    "        predictions <- list(probabilities = predictions_prob)\n",
    "        preds <- apply(predictions_prob, 1, function(row) {\n",
    "            # Get the index of the max value in the row\n",
    "            max_index <- which.max(row)\n",
    "            # Return the column name using the index\n",
    "            return(colnames(predictions_prob)[max_index])\n",
    "        })\n",
    "        # Add actual predictions to the predictions list\n",
    "        predictions$classes <- as.factor(preds)\n",
    "    }\n",
    "\n",
    "    # plot the tree\n",
    "    #rpart.plot(tree)\n",
    "\n",
    "    # Results\n",
    "    results <- list(train_set, test_set, tree, predictions)\n",
    "    names(results) <- c(\"train_set\", \"test_set\", \"tree\", \"predictions\")\n",
    "    return(results)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics for continuous target variable income\n",
    "\n",
    "evaluation_cont_single <- function(predictions, test_set){\n",
    "  MAE <- mean(abs(predictions - test_set$income))\n",
    "  MSE <- mean((predictions - test_set$income)^2)\n",
    "  RMSE <- sqrt(MSE)\n",
    "\n",
    "  SS_res <- sum((test_set$income - predictions)^2)\n",
    "  SS_tot <- sum((test_set$income - mean(test_set$income))^2)\n",
    "  R_squared <- 1 - (SS_res / SS_tot)\n",
    "\n",
    "  MAPE <- mean(abs((test_set$income - predictions) / test_set$income)) * 100\n",
    "\n",
    "  # Create a data frame for the metrics\n",
    "  evaluation_table <- data.frame(\n",
    "    Metric = c(\"Mean Absolute Error (MAE)\", \"Mean Squared Error (MSE)\", \"Root Mean Squared Error (RMSE)\",\n",
    "              \"R-squared (R²)\", \"Mean Absolute Percentage Error (MAPE)\"),\n",
    "    Value = c(MAE, MSE, RMSE, R_squared, MAPE)\n",
    "  )\n",
    "\n",
    "  # Format the values in the Value column to display without scientific notation\n",
    "  evaluation_table$Value <- as.numeric(format(evaluation_table$Value, scientific = FALSE))\n",
    "\n",
    "  # Print the evaluation table\n",
    "  return(evaluation_table)\n",
    "}\n",
    "\n",
    "## function for comparison\n",
    "\n",
    "evaluation_metrics_cont <- function(predictions_orig, test_set_orig, predictions_syn, test_set_syn){\n",
    "\n",
    "  # create table for original data\n",
    "  eval_orig <- evaluation_cont_single(predictions_orig, test_set_orig)\n",
    "  # create table for synthetic data\n",
    "  eval_syn <- evaluation_cont_single(predictions_syn, test_set_syn)\n",
    "\n",
    "  # Merge the two dataframes and set the first column as row names\n",
    "  metrics_df <- merge(eval_orig, eval_syn, by = \"Metric\", suffixes = c(\"_orig\", \"_syn\"))\n",
    "   # Set \"Metric\" column as row names\n",
    "  rownames(metrics_df) <- metrics_df$Metric\n",
    "  \n",
    "  # Remove \"Metric\" column\n",
    "  metrics_df <- metrics_df[, -1]\n",
    "  \n",
    "  # Calculate the numeric difference\n",
    "  metrics_df$Difference <- metrics_df$Value_syn - metrics_df$Value_orig\n",
    "\n",
    "  return(metrics_df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics for factored targets\n",
    "evaluation_metrics_factor <- function(predictions_orig, test_set_orig, predictions_syn, test_set_syn){\n",
    "    # confusion matrix for the prediction on original data\n",
    "    cm_orig <- confusionMatrix(predictions_orig, test_set_orig$income,\n",
    "                mode = \"everything\")\n",
    "    # confusion matrix for the prediction on synthetic data         \n",
    "    cm_syn <- confusionMatrix(predictions_syn, test_set_syn$income,\n",
    "                mode = \"everything\")\n",
    "\n",
    "    # saving evaluation metrics\n",
    "    accuracy_orig <- cm_orig$overall['Accuracy']\n",
    "    f1_orig       <- cm_orig$byClass['F1']\n",
    "    sens_orig     <- cm_orig$byClass['Sensitivity']\n",
    "    spec_orig     <- cm_orig$byClass['Specificity']\n",
    "    accuracy_syn  <- cm_syn$overall['Accuracy']\n",
    "    f1_syn        <- cm_syn$byClass['F1']\n",
    "    sens_syn      <- cm_syn$byClass['Sensitivity']\n",
    "    spec_syn      <- cm_syn$byClass['Specificity']\n",
    "\n",
    "    # Saving the differences\n",
    "    accuracy_diff <- accuracy_syn - accuracy_orig\n",
    "    f1_diff <- f1_syn - f1_orig\n",
    "    sens_diff <- sens_syn - sens_orig\n",
    "    spec_diff <- spec_syn - spec_orig\n",
    "\n",
    "    # Create the dataframe\n",
    "    metrics_df <- data.frame(\n",
    "    Metric = c(\"Accuracy\", \"F1\", \"Sensitivity\", \"Specificity\"),\n",
    "    Original = c(accuracy_orig, f1_orig, sens_orig, spec_orig),\n",
    "    Synthetic = c(accuracy_syn, f1_syn, sens_syn, spec_syn),\n",
    "    Difference = c(accuracy_diff, f1_diff, sens_diff, spec_diff)\n",
    "    )\n",
    "\n",
    "    return(metrics_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "- Für die Originaldaten wird es am Ende reichen nur einmal auf dem gleichen Seed die Prediction zu machen --> diesen Loop genau so, aber nicht wieder bei jedem Modell\n",
    "- Irgendwie einbauen den complexity parameter zu speichern\n",
    "- ggf. in der simulation nur alles einmal und den vergleich der daten (syn–orig) dann im nachhinein --> eine simulation fct für die originaldaten und eine für alle synthetischen? --> generieren der synthetischen daten weicht aber ab--> in functionsargumenten festlegen welche und diese wird dann durchlaufen? oder doch eine simulation mit allen methoden --> evtl. am ende --> würde echt lange dauern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "simulation <- function(data, method = \"cart\", k = nrow(data), nrun = 5, k_fold = 10, steps = 10){\n",
    "\n",
    "  # create array to save the synthetic data\n",
    "  syn_data <- array(data = NA, dim = c(k, ncol(data), nrun)) #, dimnames = list(\"row\", \"colum\", \"run\"))\n",
    "  # create empty vectors to safe trees\n",
    "  tree_orig <- list()\n",
    "  tree_syn <- list()\n",
    "  # create vectors to safe loss\n",
    "  loss_orig <- rep(0, steps)\n",
    "  loss_syn <- rep(0, steps)\n",
    "  # create empty array to store cp values chosen\n",
    "  cp_vals <- array(data = NA, dim = c(nrun, 2))\n",
    "  # create empty list to store evaluation dataframes\n",
    "  eval_list <- list()\n",
    "\n",
    "  # for loss-calculation factored variables need to be converted to numeric\n",
    "  if (is.factor(data$income)) {\n",
    "    data$income <- as.factor(as.numeric(data$income == \">50K\" ))\n",
    "  }\n",
    "\n",
    "  s <- 1234\n",
    "  for (i in 1:nrun){\n",
    "    # vary seed with each run\n",
    "    s <- s + 1\n",
    "\n",
    "    # generate synthetic data\n",
    "    gen_data <- syn(data = data, method = method, k = k, seed = s)\n",
    "    # save the data from each run\n",
    "    syn_data[,,i] <- as.matrix(gen_data$syn)\n",
    "\n",
    "    # for each fold add up loss, choose the parameter for which the loss is smallest\n",
    "    # loop over different cp values?? It is pretty obv that loss will just get smaller with smaller cp values\n",
    "\n",
    "    complexity <- seq(0.0001, 0.01, length.out = steps)\n",
    "    \n",
    "    # Randomly split the data set into k-subsets (or k-fold)\n",
    "    data_orig <- as.data.frame(data)\n",
    "    data_syn <- as.data.frame(gen_data$syn)\n",
    "    datalist_orig <- split(data_orig, sample(1:k_fold, nrow(data_orig), replace=T)) #list of k same-sized elements that are slices of the data\n",
    "    datalist_syn <- split(data_syn, sample(1:k_fold, nrow(data_syn), replace=T)) #list of k same-sized elements that are slices of the data\n",
    "\n",
    "    # leave-one-out CV for prediction\n",
    "    for (j in 1:k_fold) {\n",
    "      #split data in k folds\n",
    "      data_val_orig <- datalist_orig[[j]]    #j-th of the k folds, validation set\n",
    "      data_train_orig <- datalist_orig[-j]   #rest of the data without j-th of the k folds, training set\n",
    "      data_train_orig <- bind_rows(data_train_orig) #convert list to dataframe\n",
    "      data_val_syn <- datalist_syn[[j]]    #j-th of the k folds, validation set\n",
    "      data_train_syn <- datalist_syn[-j]   #rest of the data without j-th of the k folds, training set\n",
    "      data_train_syn <- bind_rows(data_train_syn) #convert list to dataframe\n",
    "\n",
    "      # optional parameters to prevent overfitting: minbucket, minsplit, maxdepth\n",
    "      for (l in 1:length(complexity)){\n",
    "        # create income prediction with orig. data\n",
    "        tree_orig[[l]] <- rpart(income ~ ., data = data_train_orig, cp = complexity[l])\n",
    "        # create income prediction with syn. data\n",
    "        tree_syn[[l]] <- rpart(income ~ ., data = data_train_syn, cp = complexity[l])\n",
    "        \n",
    "        # Predict on the test set\n",
    "        predictions_orig <- predict(tree_orig[l], data_val_orig)\n",
    "        predictions_syn <- predict(tree_syn[l], data_val_syn)\n",
    "        print(\"dim predictions\")\n",
    "        print(dim(predictions_orig))\n",
    "        #print(class(predictions_orig))\n",
    "        #print(predictions_orig)\n",
    "\n",
    "        # safe some loss information and sum over the k-fold loops\n",
    "        if (is.numeric(data$income)) {\n",
    "          # Mean Squared Error\n",
    "          loss_orig[l] <- loss_orig[l] + mean((predictions_orig - tree_orig[[l]]$test_set$income)^2)\n",
    "          loss_syn[l] <- loss_syn[l] + mean((predictions_syn - tree_syn[[l]]$test_set$income)^2)\n",
    "        }\n",
    "        else if (is.factor(data$income)) {\n",
    "          # Cross-Entropy Loss\n",
    "          epsilon <- 1e-15  # to prevent log(0) which is undefined\n",
    "          predicted_probs <- pmax(pmin(predictions_orig[,2], 1 - epsilon), epsilon)\n",
    "          n <- length(predicted_probs)\n",
    "          loss_orig[l] <- loss_orig[l] + (-sum(tree_orig[[l]]$test_set$income * log(predicted_probs) + (1 - tree_orig[[l]]$test_set$income) * log(1 - predicted_probs)) / n)\n",
    "          predicted_probs <- pmax(pmin(predictions_syn, 1 - epsilon), epsilon)\n",
    "          loss_syn[l] <- loss_syn[l] + (-sum(tree_syn[[l]]$test_set$income * log(predicted_probs) + (1 - tree_syn[[l]]$test_set$income) * log(1 - predicted_probs)) / n)\n",
    "        }\n",
    "        else {\n",
    "          break(\"The predicted target has to be numeric or factor.\")\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    # safe only the tree with the minimal loss\n",
    "    min_orig  <- which(loss_orig==min(loss_orig), arr.ind = TRUE)\n",
    "    min_syn  <- which(loss_syn==min(loss_syn), arr.ind = TRUE)\n",
    "    # safe the cp value for the tree with the minimal loss\n",
    "    cp_vals[i,] <- c(complexity[min_orig], complexity[min_syn])\n",
    "\n",
    "    train_index_orig <- sample(1:nrow(data), nrow(data)*trainsplit)\n",
    "    # train dataset formation\n",
    "    train_set_orig <- data[train_index_orig, ]\n",
    "    # test dataset formation\n",
    "    test_set_orig <- data[-train_index_orig, ]\n",
    "\n",
    "    train_index_syn <- sample(1:nrow(gen_data$syn), nrow(gen_data$syn)*trainsplit)\n",
    "    # train dataset formation\n",
    "    train_set_syn <- gen_data$syn[train_index_syn, ]\n",
    "    # test dataset formation\n",
    "    test_set_syn <- gen_data$syn[-train_index_syn, ]\n",
    "\n",
    "    tree_o <- build_tree(data = data, cp = complexity[min_orig])\n",
    "    tree_s <- build_tree(data = data, cp = complexity[min_syn])\n",
    "    \n",
    "    # evaluate the difference\n",
    "    if (is.numeric(data$income)) {\n",
    "      eval <- as.data.frame(evaluation_metrics_cont(predictions_orig, test_set_orig, predictions_syn, test_set_syn))\n",
    "    }\n",
    "    else if (is.factor(data$income)) {\n",
    "      predictions_orig <- apply(predictions_orig, 1, function(row) {\n",
    "            # Get the index of the max value in the row\n",
    "            max_index <- which.max(row)\n",
    "            # Return the column name using the index\n",
    "            return(colnames(predictions_orig)[max_index])\n",
    "            })\n",
    "      predictions_syn <- apply(predictions_syn, 1, function(row) {\n",
    "            # Get the index of the max value in the row\n",
    "            max_index <- which.max(row)\n",
    "            # Return the column name using the index\n",
    "            return(colnames(predictions_syn)[max_index])\n",
    "            })\n",
    "      eval <- as.data.frame(evaluation_metrics_factor(predictions_orig, test_set_orig, predictions_syn, test_set_syn))\n",
    "    }\n",
    "    else {\n",
    "       break(\"The predicted target has to be numeric or factor.\")\n",
    "    }\n",
    "\n",
    "    eval_list[[i]] <- eval\n",
    "\n",
    "    print(c(\"run\", i, \"completed\"))\n",
    "  }\n",
    "  \n",
    "  # now average all dataframes in eval_list\n",
    "  sum_df <- Reduce(function(x, y) Map(`+`, x, y), eval_list)\n",
    "  eval_avg <- lapply(sum_df, function(col) col / length(eval_list))\n",
    "\n",
    "  # Convert the list back to a dataframe\n",
    "  # Store row names\n",
    "  rownames <- row.names(eval_list[[1]])\n",
    "\n",
    "  # Convert the list back to a dataframe\n",
    "  eval_avg <- as.data.frame(eval_avg)\n",
    "\n",
    "  # Set back the row names\n",
    "  row.names(eval_avg) <- rownames\n",
    "\n",
    "  # returns\n",
    "  results <- list(eval_avg = eval_avg, syn_data = syn_data, cp_vals = cp_vals)\n",
    "  return(results)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpart.control              package:rpart               R Documentation\n",
      "\n",
      "_\bC_\bo_\bn_\bt_\br_\bo_\bl _\bf_\bo_\br _\bR_\bp_\ba_\br_\bt _\bF_\bi_\bt_\bs\n",
      "\n",
      "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
      "\n",
      "     Various parameters that control aspects of the 'rpart' fit.\n",
      "\n",
      "_\bU_\bs_\ba_\bg_\be:\n",
      "\n",
      "     rpart.control(minsplit = 20, minbucket = round(minsplit/3), cp = 0.01, \n",
      "                   maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10,\n",
      "                   surrogatestyle = 0, maxdepth = 30, ...)\n",
      "     \n",
      "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
      "\n",
      "minsplit: the minimum number of observations that must exist in a node\n",
      "          in order for a split to be attempted.\n",
      "\n",
      "minbucket: the minimum number of observations in any terminal '<leaf>'\n",
      "          node.  If only one of 'minbucket' or 'minsplit' is specified,\n",
      "          the code either sets 'minsplit' to 'minbucket*3' or\n",
      "          'minbucket' to 'minsplit/3', as appropriate.\n",
      "\n",
      "      cp: complexity parameter.  Any split that does not decrease the\n",
      "          overall lack of fit by a factor of 'cp' is not attempted.\n",
      "          For instance, with 'anova' splitting, this means that the\n",
      "          overall R-squared must increase by 'cp' at each step. The\n",
      "          main role of this parameter is to save computing time by\n",
      "          pruning off splits that are obviously not worthwhile.\n",
      "          Essentially,the user informs the program that any split which\n",
      "          does not improve the fit by 'cp' will likely be pruned off by\n",
      "          cross-validation, and that hence the program need not pursue\n",
      "          it.\n",
      "\n",
      "maxcompete: the number of competitor splits retained in the output.  It\n",
      "          is useful to know not just which split was chosen, but which\n",
      "          variable came in second, third, etc.\n",
      "\n",
      "maxsurrogate: the number of surrogate splits retained in the output.\n",
      "          If this is set to zero the compute time will be reduced,\n",
      "          since approximately half of the computational time (other\n",
      "          than setup) is used in the search for surrogate splits.\n",
      "\n",
      "usesurrogate: how to use surrogates in the splitting process.  '0'\n",
      "          means display only; an observation with a missing value for\n",
      "          the primary split rule is not sent further down the tree.\n",
      "          '1' means use surrogates, in order, to split subjects missing\n",
      "          the primary variable; if all surrogates are missing the\n",
      "          observation is not split.  For value '2' ,if all surrogates\n",
      "          are missing, then send the observation in the majority\n",
      "          direction.  A value of '0' corresponds to the action of\n",
      "          'tree', and '2' to the recommendations of Breiman _et.al_\n",
      "          (1984).\n",
      "\n",
      "    xval: number of cross-validations.\n",
      "\n",
      "surrogatestyle: controls the selection of a best surrogate.  If set to\n",
      "          '0' (default) the program uses the total number of correct\n",
      "          classification for a potential surrogate variable, if set to\n",
      "          '1' it uses the percent correct, calculated over the\n",
      "          non-missing values of the surrogate.  The first option more\n",
      "          severely penalizes covariates with a large number of missing\n",
      "          values.\n",
      "\n",
      "maxdepth: Set the maximum depth of any node of the final tree, with the\n",
      "          root node counted as depth 0.  Values greater than 30 'rpart'\n",
      "          will give nonsense results on 32-bit machines.\n",
      "\n",
      "     ...: mop up other arguments.\n",
      "\n",
      "_\bV_\ba_\bl_\bu_\be:\n",
      "\n",
      "     A list containing the options.\n",
      "\n",
      "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
      "\n",
      "     'rpart'\n"
     ]
    }
   ],
   "source": [
    "?rpart.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] \"dim predictions\"\n",
      "NULL\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in predictions_orig[, 2]: falsche Anzahl von Dimensionen\n",
     "output_type": "error",
     "traceback": [
      "Error in predictions_orig[, 2]: falsche Anzahl von Dimensionen\nTraceback:\n",
      "1. simulation(adult, nrun = 2, k_fold = 5, steps = 10)",
      "2. pmax(pmin(predictions_orig[, 2], 1 - epsilon), epsilon)   # at line 76 of file <text>",
      "3. pmin(predictions_orig[, 2], 1 - epsilon)   # at line 76 of file <text>"
     ]
    }
   ],
   "source": [
    "adult_res <- simulation(adult, nrun = 2, k_fold = 5, steps = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"1\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"2\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"3\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"4\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"5\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"6\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"7\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"8\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"9\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"10\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"11\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"12\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"13\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"14\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"15\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"16\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"17\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"18\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"19\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] \"run\"       \"20\"        \"completed\"\n"
     ]
    }
   ],
   "source": [
    "cps_res <- simulation(cpspop, nrun = 20, k_fold = 5, steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 20 x 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.0023</td><td>0.0023</td></tr>\n",
       "\t<tr><td>0.0023</td><td>0.0023</td></tr>\n",
       "\t<tr><td>0.0023</td><td>0.0023</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "\t<tr><td>0.0012</td><td>0.0012</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 20 x 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t 0.0023 & 0.0023\\\\\n",
       "\t 0.0023 & 0.0023\\\\\n",
       "\t 0.0023 & 0.0023\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\t 0.0012 & 0.0012\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 20 x 2 of type dbl\n",
       "\n",
       "| 0.0023 | 0.0023 |\n",
       "| 0.0023 | 0.0023 |\n",
       "| 0.0023 | 0.0023 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "| 0.0012 | 0.0012 |\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]   [,2]  \n",
       " [1,] 0.0023 0.0023\n",
       " [2,] 0.0023 0.0023\n",
       " [3,] 0.0023 0.0023\n",
       " [4,] 0.0012 0.0012\n",
       " [5,] 0.0012 0.0012\n",
       " [6,] 0.0012 0.0012\n",
       " [7,] 0.0012 0.0012\n",
       " [8,] 0.0012 0.0012\n",
       " [9,] 0.0012 0.0012\n",
       "[10,] 0.0012 0.0012\n",
       "[11,] 0.0012 0.0012\n",
       "[12,] 0.0012 0.0012\n",
       "[13,] 0.0012 0.0012\n",
       "[14,] 0.0012 0.0012\n",
       "[15,] 0.0012 0.0012\n",
       "[16,] 0.0012 0.0012\n",
       "[17,] 0.0012 0.0012\n",
       "[18,] 0.0012 0.0012\n",
       "[19,] 0.0012 0.0012\n",
       "[20,] 0.0012 0.0012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cps_res$cp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 x 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Value_orig</th><th scope=col>Value_syn</th><th scope=col>Difference</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Mean Absolute Error (MAE)</th><td>2.611207e+04</td><td>2.603615e+04</td><td>-7.591627e+01</td></tr>\n",
       "\t<tr><th scope=row>Mean Absolute Percentage Error (MAPE)</th><td>4.492630e+03</td><td>3.530684e+03</td><td>-9.619463e+02</td></tr>\n",
       "\t<tr><th scope=row>Mean Squared Error (MSE)</th><td>1.675107e+09</td><td>1.686016e+09</td><td> 1.090891e+07</td></tr>\n",
       "\t<tr><th scope=row>R-squared (R&lt;U+00B2&gt;)</th><td>3.066210e-01</td><td>3.114957e-01</td><td> 4.874735e-03</td></tr>\n",
       "\t<tr><th scope=row>Root Mean Squared Error (RMSE)</th><td>4.091698e+04</td><td>4.105264e+04</td><td> 1.356675e+02</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 x 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Value\\_orig & Value\\_syn & Difference\\\\\n",
       "  & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tMean Absolute Error (MAE) & 2.611207e+04 & 2.603615e+04 & -7.591627e+01\\\\\n",
       "\tMean Absolute Percentage Error (MAPE) & 4.492630e+03 & 3.530684e+03 & -9.619463e+02\\\\\n",
       "\tMean Squared Error (MSE) & 1.675107e+09 & 1.686016e+09 &  1.090891e+07\\\\\n",
       "\tR-squared (R<U+00B2>) & 3.066210e-01 & 3.114957e-01 &  4.874735e-03\\\\\n",
       "\tRoot Mean Squared Error (RMSE) & 4.091698e+04 & 4.105264e+04 &  1.356675e+02\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 x 3\n",
       "\n",
       "| <!--/--> | Value_orig &lt;dbl&gt; | Value_syn &lt;dbl&gt; | Difference &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| Mean Absolute Error (MAE) | 2.611207e+04 | 2.603615e+04 | -7.591627e+01 |\n",
       "| Mean Absolute Percentage Error (MAPE) | 4.492630e+03 | 3.530684e+03 | -9.619463e+02 |\n",
       "| Mean Squared Error (MSE) | 1.675107e+09 | 1.686016e+09 |  1.090891e+07 |\n",
       "| R-squared (R&lt;U+00B2&gt;) | 3.066210e-01 | 3.114957e-01 |  4.874735e-03 |\n",
       "| Root Mean Squared Error (RMSE) | 4.091698e+04 | 4.105264e+04 |  1.356675e+02 |\n",
       "\n"
      ],
      "text/plain": [
       "                                      Value_orig   Value_syn    Difference   \n",
       "Mean Absolute Error (MAE)             2.611207e+04 2.603615e+04 -7.591627e+01\n",
       "Mean Absolute Percentage Error (MAPE) 4.492630e+03 3.530684e+03 -9.619463e+02\n",
       "Mean Squared Error (MSE)              1.675107e+09 1.686016e+09  1.090891e+07\n",
       "R-squared (R<U+00B2>)                 3.066210e-01 3.114957e-01  4.874735e-03\n",
       "Root Mean Squared Error (RMSE)        4.091698e+04 4.105264e+04  1.356675e+02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cps_res$eval_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "adult_res$cp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "adult_res$eval_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Saving the data:\n",
    "saveRDS(cps_res, file = (paste0(here(), \"/simulation/cps_CART_res.RData\")))\n",
    "saveRDS(adult_res, file = (paste0(here(), \"/simulation/adult_CART_res.RData\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

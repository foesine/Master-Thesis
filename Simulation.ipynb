{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "With R kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further info\n",
    "Models usable with train() from caret: <br>\n",
    "https://topepo.github.io/caret/train-models-by-tag.html#Model_Tree <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lade n\"otiges Paket: Hmisc\n",
      "\n",
      "Warning message:\n",
      "\"Paket 'Hmisc' wurde unter R Version 4.3.2 erstellt\"\n",
      "\n",
      "Attache Paket: 'Hmisc'\n",
      "\n",
      "\n",
      "Das folgende Objekt ist maskiert 'package:pracma':\n",
      "\n",
      "    ceil\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:dplyr':\n",
      "\n",
      "    src, summarize\n",
      "\n",
      "\n",
      "Die folgenden Objekte sind maskiert von 'package:base':\n",
      "\n",
      "    format.pval, units\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "9. TRUE\n",
       "10. TRUE\n",
       "11. TRUE\n",
       "12. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] TRUE\n",
       "\n",
       "[[5]]\n",
       "[1] TRUE\n",
       "\n",
       "[[6]]\n",
       "[1] TRUE\n",
       "\n",
       "[[7]]\n",
       "[1] TRUE\n",
       "\n",
       "[[8]]\n",
       "[1] TRUE\n",
       "\n",
       "[[9]]\n",
       "[1] TRUE\n",
       "\n",
       "[[10]]\n",
       "[1] TRUE\n",
       "\n",
       "[[11]]\n",
       "[1] TRUE\n",
       "\n",
       "[[12]]\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ".libPaths(\"/user/emma.foessing01/u11969/R_libs\")\n",
    "Sys.setenv(\"PKG_CXXFLAGS\"=\"-std=c++14\")\n",
    "\n",
    "install.packages(\"synthpop\")\n",
    "\n",
    "# Load libraries\n",
    "list_of_packages <- c(\n",
    "  \"synthpop\", \"insight\", \"party\", \"haven\", \"dplyr\", \"rpart\", \"rpart.plot\",\n",
    "  \"randomForest\", \"pROC\", \"caret\", \"pracma\", \"here\", \"Hmisc\", \"purrr\",\n",
    "  \"ranger\", \"bnlearn\", \"arulesCBA\", \"network\", \"igraph\", \"xgboost\",\n",
    "  \"data.table\", \"RSNNS\"\n",
    ")\n",
    "# Function to check and install packages\n",
    "install_if_missing <- function(p) {\n",
    "  if (!requireNamespace(p, quietly = TRUE)) {\n",
    "    install.packages(p, dependencies = TRUE)\n",
    "  }\n",
    "  library(p, character.only = TRUE)\n",
    "}\n",
    "\n",
    "# Install and load all required packages\n",
    "lapply(list_of_packages, install_if_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# set path\n",
    "############## adjust to correct directory!\n",
    "directory <- \"/user/emma.foessing01/u11969/Master-Thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(file = (paste0(directory, \"/cpspop.RData\")))\n",
    "adult <- read.csv(file = (directory,\"/adult_preprocessed.csv\")))\n",
    "# delete NAs\n",
    "adult[adult == \"?\"] <- NA\n",
    "adult <- na.omit(adult)\n",
    "\n",
    "adult$workclass <- as.factor(adult$workclass)\n",
    "adult$education <- as.factor(adult$education)\n",
    "adult$marital_status <- as.factor(adult$marital_status)\n",
    "adult$relationship <- as.factor(adult$relationship)\n",
    "adult$race <- as.factor(adult$race)\n",
    "adult$sex <- as.factor(adult$sex)\n",
    "adult$native_country <- as.factor(adult$native_country)\n",
    "adult$income <- as.factor(adult$income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Datensatz zu genieren (m = 1) ist ausreichend, da ich keine Varianzanalyse machen werde. Damit die Ergebnisse nicht von einem zufälligen Prozess abhängen ist es sinnvoll über ein paar runs Mittelwerte zu bilden (50–100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics for continuous targets\n",
    "evaluation_metrics_cont <- function(predictions, test_set){\n",
    "  MAE <- mean(abs(predictions - test_set$income))\n",
    "  MSE <- mean((predictions - test_set$income)^2)\n",
    "  RMSE <- sqrt(MSE)\n",
    "\n",
    "  SS_res <- sum((test_set$income - predictions)^2)\n",
    "  SS_tot <- sum((test_set$income - mean(test_set$income))^2)\n",
    "  R_squared <- 1 - (SS_res / SS_tot)\n",
    "\n",
    "  MAPE <- mean(abs((test_set$income - predictions) / test_set$income)) * 100\n",
    "\n",
    "  # Create the dataframe\n",
    "  metrics_df <- data.frame(\n",
    "        MAE = MAE, \n",
    "        MSE = MSE, \n",
    "        RMSE = RMSE,\n",
    "        R_squared = R_squared, \n",
    "        MAPE = MAPE)\n",
    "\n",
    "  return(metrics_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics for factored targets\n",
    "evaluation_metrics_factor <- function(predictions, test_set){\n",
    "    # confusion matrix for the prediction on original data\n",
    "    cm <- confusionMatrix(predictions, test_set$income,\n",
    "                mode = \"everything\")\n",
    "\n",
    "    # saving evaluation metrics\n",
    "    accuracy <- cm$overall['Accuracy']\n",
    "    f1 <- cm$byClass['F1']\n",
    "    sens <- cm$byClass['Sensitivity']\n",
    "    spec <- cm$byClass['Specificity']\n",
    "\n",
    "    # Create the dataframe\n",
    "    metrics_df <- data.frame(\n",
    "        Accuracy = accuracy, \n",
    "        F1 = f1, \n",
    "        Sensitivity = sens, \n",
    "        Specificity = spec\n",
    "    )\n",
    "    \n",
    "    return(metrics_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# just the prediction\n",
    "cart_pred <- function(data, outer_folds, cp_steps, inner_folds){############adjust##############\n",
    "    # adjust evaluation metric to fit both numeric and factored targets\n",
    "    summaryFunctionType <- if (is.numeric(data$income)) defaultSummary else multiClassSummary\n",
    "    # metric: train() uses per default RSME and Accuracy for numeric and factored targets\n",
    "\n",
    "    #  set control args\n",
    "    outer_control <- trainControl(method = \"cv\", number = outer_folds,\n",
    "                                  summaryFunction = summaryFunctionType,\n",
    "                                  verboseIter = FALSE,\n",
    "                                  allowParallel = TRUE)\n",
    "        \n",
    "    inner_control <- trainControl(method = \"cv\", number = inner_folds, \n",
    "                                  summaryFunction = summaryFunctionType,\n",
    "                                  verboseIter = FALSE,\n",
    "                                  allowParallel = TRUE)\n",
    "\n",
    "    # Define the grid for hyperparameter tuning\n",
    "    complexity <- 10^seq(log10(0.0001), log10(0.01), length.out = cp_steps)############adjust##############\n",
    "\n",
    "    # Create grid\n",
    "    tunegrid <- expand.grid(cp = complexity)############adjust##############\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    outer_results <- list()\n",
    "\n",
    "    outer_cv_folds = createFolds(data$income, k = outer_folds)\n",
    "    \n",
    "    # Outer loop: Cross-validation for model evaluation\n",
    "    for (i in seq_along(outer_folds)) {\n",
    "        \n",
    "        # Split data into outer folds\n",
    "        outer_test_index = outer_cv_folds[[i]]\n",
    "        outer_testData = data[outer_test_index,]\n",
    "        outer_trainData  = data[-outer_test_index,]\n",
    "        \n",
    "        # Hyperparameter tuning using inner CV\n",
    "        # No need for inner loop because \"train\" does k-fold CV already\n",
    "        model <- caret::train(income ~ ., \n",
    "                        data = outer_trainData, \n",
    "                        method = \"rpart\", ############adjust##############\n",
    "                        tuneGrid = tunegrid, \n",
    "                        trControl = inner_control,\n",
    "                        control = rpart.control(maxsurrogate = 0, maxcompete = 1) ############adjust##############\n",
    "                        )#,\n",
    "                        #metric = metricType)\n",
    "            \n",
    "\n",
    "        # Store the best hyperparameters\n",
    "        best_hyperparameters <- model$bestTune\n",
    "\n",
    "        # Train the final model on the outer training set with the best hyperparameters\n",
    "        final_model <- caret::train(income ~ ., \n",
    "                             data = outer_trainData, \n",
    "                             method = \"rpart\",############adjust##############\n",
    "                             trControl = outer_control, \n",
    "                             tuneGrid = best_hyperparameters)\n",
    "\n",
    "        # Testing the final model on the outer test set\n",
    "        predictions <- predict(final_model, newdata = outer_testData)\n",
    "        \n",
    "        if (is.numeric(data$income)) {\n",
    "            eval <- postResample(predictions, outer_testData$income) # postResample is a useful caret function\n",
    "        } else if (is.factor(data$income)) {\n",
    "            eval <- confusionMatrix(predictions, outer_testData$income)\n",
    "        } else {\n",
    "            stop(\"The predicted target has to be numeric or factor.\")\n",
    "        }\n",
    "\n",
    "        # Store the evaluation metrics for this outer fold\n",
    "        outer_results[[i]] <- eval\n",
    "    }\n",
    "\n",
    "    # Average the evaluation metrics over the outer folds\n",
    "    eval_avg_outer_fold <- mean(unlist(outer_results)) # Calculate the mean performance over all outer folds\n",
    "\n",
    "    # Return the average evaluation metrics\n",
    "    return(eval_avg_outer_fold)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# just the prediction\n",
    "rf_pred <- function(data, outer_folds, mtry_steps, ntree_steps, inner_folds){############adjust##############\n",
    "    # adjust evaluation metric to fit both numeric and factored targets\n",
    "    summaryFunctionType <- if (is.numeric(data$income)) defaultSummary else multiClassSummary\n",
    "    # metric: train() uses per default RSME and Accuracy for numeric and factored targets\n",
    "\n",
    "    #  set control args\n",
    "    outer_control <- trainControl(method = \"cv\", number = outer_folds,\n",
    "                                  summaryFunction = summaryFunctionType,\n",
    "                                  verboseIter = FALSE,\n",
    "                                  allowParallel = TRUE)\n",
    "        \n",
    "    inner_control <- trainControl(method = \"cv\", number = inner_folds, \n",
    "                                  summaryFunction = summaryFunctionType,\n",
    "                                  verboseIter = FALSE,\n",
    "                                  allowParallel = TRUE)\n",
    "\n",
    "    # Define the parameter grid for tuning\n",
    "    splitrule_value <- if (is.numeric(data$income)) \"variance\" else \"gini\"\n",
    "    \n",
    "    tunegrid <- expand.grid(mtry = seq(2, ncol(data) - 1, length.out = mtry_steps),\n",
    "    splitrule = splitrule_value,\n",
    "    min.node.size = 5)\n",
    "    #ntree_steps noch einbauen?\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    outer_results <- list()\n",
    "\n",
    "    outer_cv_folds = createFolds(data$income, k = outer_folds)\n",
    "    \n",
    "    # Outer loop: Cross-validation for model evaluation\n",
    "    for (i in seq_along(outer_folds)) {\n",
    "        \n",
    "        # Split data into outer folds\n",
    "        outer_test_index = outer_cv_folds[[i]]\n",
    "        outer_testData = data[outer_test_index,]\n",
    "        outer_trainData  = data[-outer_test_index,]\n",
    "        \n",
    "        # Hyperparameter tuning using inner CV\n",
    "        # No need for inner loop because \"train\" does k-fold CV already\n",
    "        model <- caret::train(income ~ ., \n",
    "                        data = outer_trainData, \n",
    "                        method = \"ranger\", ############adjust##############\n",
    "                        tuneGrid = tunegrid, \n",
    "                        trControl = inner_control)#,\n",
    "                        #metric = metricType)\n",
    "            \n",
    "\n",
    "        # Store the best hyperparameters\n",
    "        best_hyperparameters <- model$bestTune\n",
    "\n",
    "        # Train the final model on the outer training set with the best hyperparameters\n",
    "        final_model <- caret::train(income ~ ., \n",
    "                             data = outer_trainData, \n",
    "                             method = \"ranger\",############adjust##############\n",
    "                             trControl = outer_control, \n",
    "                             tuneGrid = best_hyperparameters)\n",
    "\n",
    "        # Testing the final model on the outer test set\n",
    "        predictions <- predict(final_model, newdata = outer_testData)\n",
    "        \n",
    "        if (is.numeric(data$income)) {\n",
    "            eval <- postResample(predictions, outer_testData$income) # postResample is a useful caret function\n",
    "        } else if (is.factor(data$income)) {\n",
    "            eval <- confusionMatrix(predictions, outer_testData$income)\n",
    "        } else {\n",
    "            stop(\"The predicted target has to be numeric or factor.\")\n",
    "        }\n",
    "\n",
    "        # Store the evaluation metrics for this outer fold\n",
    "        outer_results[[i]] <- eval\n",
    "    }\n",
    "\n",
    "    # Average the evaluation metrics over the outer folds\n",
    "    eval_avg_outer_fold <- mean(unlist(outer_results)) # Calculate the mean performance over all outer folds\n",
    "\n",
    "    # Return the average evaluation metrics\n",
    "    return(eval_avg_outer_fold)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#boost_pred <-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#bn_pred <-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#mlp_pred <-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "simulation <- function(data, nrun = 10, outer_folds, inner_folds, mtry_steps = 10, ntree_steps= 10, cp_steps = 10){\n",
    "    \n",
    "    # create empty list to store evaluation dataframes\n",
    "    eval_list <- list()\n",
    "\n",
    "    # set inital seed\n",
    "    s <- 1234\n",
    "    for (i in 1:nrun){\n",
    "        # vary seed with each run\n",
    "        s <- s + 1\n",
    "\n",
    "        # create synthetic data\n",
    "        # data <- gen_data()\n",
    "\n",
    "        # prediction model with nested CV and grid search\n",
    "        CART_eval <- cart_pred(data, outer_folds, cp_steps, inner_folds)\n",
    "        RF_eval <- rf_pred(data, outer_folds, mtry_steps, ntree_steps, inner_folds)\n",
    "        #Boost_eval <-\n",
    "        #BN_eval <-\n",
    "        #MLP_eval <-\n",
    "\n",
    "        # bind results \n",
    "        eval <- rbind(CART_eval = CART_eval, RF_eval = RF_eval)#, Boost_eval = Boost_eval, BN_eval = BN_eval, MLP_eval = MLP_eval)\n",
    "\n",
    "        # ich glaube wenn es so verschachtelt ist und ich eine Liste und noch eine Liste habe, müsste ich es anders machen\n",
    "        # am besten wäre ein Dataframe und für jede Model-Art eine Zeile\n",
    "        eval_list[[i]] <- eval\n",
    "        print(c(\"run\", i, \"completed\"))\n",
    "        }\n",
    "\n",
    "    # average over all runs\n",
    "    sum_df <- Reduce(function(x, y) Map(`+`, x, y), eval_list)\n",
    "    eval_avg <- lapply(sum_df, function(col) col / length(eval_list))\n",
    "\n",
    "    # Convert the list back to a dataframe\n",
    "    # Store row names\n",
    "    rownames <- row.names(eval_list[[1]])\n",
    "\n",
    "    # Convert the list back to a dataframe\n",
    "    eval_avg <- as.data.frame(eval_avg)\n",
    "\n",
    "    # Set back the row names\n",
    "    row.names(eval_avg) <- rownames\n",
    "    \n",
    "    # returns\n",
    "    results <- list(eval_avg = eval_avg)\n",
    "    return(results)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "simulation <- function(data, nrun = 10, k_fold = 10, steps = 10){\n",
    "    # create array to save the synthetic data\n",
    "    # syn_data <- array(data = NA, dim = c(k, ncol(data), nrun)) # not necessary, but in case it's wanted\n",
    "    # create empty vector to safe trees\n",
    "    tree <- list()\n",
    "    # create vector to safe loss\n",
    "    loss <- rep(0, steps)\n",
    "    # create empty array to store cp values chosen\n",
    "    cp_val <- rep(0, nrun)\n",
    "    # create empty list to store evaluation dataframes\n",
    "    eval_list <- list()\n",
    "\n",
    "    # set the complexity parameters for trees\n",
    "    complexity <- 10^seq(log10(0.0001), log10(0.01), length.out = steps)\n",
    "\n",
    "    # for loss-calculation factored variables need to be converted to numeric\n",
    "    if (is.factor(data$income)) {\n",
    "        data$income <- as.factor(as.numeric(data$income == \">50K\"))\n",
    "    }\n",
    "\n",
    "    # set inital seed\n",
    "    s <- 1234\n",
    "    for (i in 1:nrun){\n",
    "        # vary seed with each run\n",
    "        s <- s + 1\n",
    "\n",
    "        # generate synthetic data\n",
    "        gen_data <- syn(data = data, k = nrow(data), seed = s)\n",
    "        # save the data from each run if wanted\n",
    "        # syn_data[,,i] <- as.matrix(gen_data$syn)\n",
    "\n",
    "        # Randomly split the data set into k-subsets (or k-fold)\n",
    "        data_syn <- as.data.frame(gen_data$syn) # try without this?\n",
    "        datalist_syn <- split(gen_data$syn, sample(1:k_fold, nrow(gen_data$syn), replace=T)) #list of k same-sized elements that are slices of the data\n",
    "        \n",
    "        # leave-one-out CV for prediction\n",
    "        for (j in 1:k_fold) {\n",
    "            # split data in k folds\n",
    "            data_val <- datalist_syn[[j]]               # j-th of the k folds, validation set\n",
    "            data_train <- bind_rows(datalist_syn[-j])   #rest of the data without j-th of the k folds, training set\n",
    "\n",
    "            # optional parameters to prevent overfitting: minbucket, minsplit, maxdepth\n",
    "            for (l in 1:length(complexity)){\n",
    "                # create income prediction tree with train data\n",
    "                tree[[l]] <- rpart(income ~ ., data = data_train, cp = complexity[l], control = rpart.control(maxsurrogate = 0, maxcompete = 1))\n",
    "                # Predict on the validation set\n",
    "                predictions <- predict(tree[[l]], data_val)\n",
    "\n",
    "                # safe some loss information and sum over the k-fold loops\n",
    "                if (is.numeric(data$income)) {\n",
    "                    # Mean Squared Error\n",
    "                    loss[l] <- loss[l] + mean((predictions - data_val$income)^2)\n",
    "                    }\n",
    "                else if (is.factor(data$income)) {\n",
    "                    # Cross-Entropy Loss\n",
    "                    epsilon <- 1e-15  # to prevent log(0) which is undefined\n",
    "                    predicted_probs <- pmax(pmin(predictions[,2], 1 - epsilon), epsilon)\n",
    "                    n <- length(predicted_probs)\n",
    "                    loss[l] <- loss[l] + (-sum(as.numeric(data_val$income) * log(predicted_probs) + (1 - as.numeric(data_val$income)) * log(1 - predicted_probs)) / n)\n",
    "                    }\n",
    "                else {\n",
    "                    break(\"The predicted target has to be numeric or factor.\")\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        # for which cp value was the loss the smallest\n",
    "        min_loss <- which.min(loss)\n",
    "        print(min_loss)\n",
    "        cp_val[i] <- c(complexity[min_loss])\n",
    "\n",
    "        tree_s <- build_tree(data = gen_data$syn, cp = cp_val[i])\n",
    "    \n",
    "        # evaluation metrics\n",
    "        if (is.numeric(data$income)) {\n",
    "            eval <- as.data.frame(evaluation_metrics_cont(tree_s$predictions, tree_s$test_set))\n",
    "            }\n",
    "        else if (is.factor(data$income)) {\n",
    "            eval <- as.data.frame(evaluation_metrics_factor(tree_s$predictions$classes, tree_s$test_set))\n",
    "            }\n",
    "        else {\n",
    "            break(\"The predicted target has to be numeric or factor.\")\n",
    "            }\n",
    "\n",
    "        eval_list[[i]] <- eval\n",
    "        print(c(\"run\", i, \"completed\"))\n",
    "        }\n",
    "\n",
    "    # average over all runs\n",
    "    sum_df <- Reduce(function(x, y) Map(`+`, x, y), eval_list)\n",
    "    eval_avg <- lapply(sum_df, function(col) col / length(eval_list))\n",
    "\n",
    "    # Convert the list back to a dataframe\n",
    "    # Store row names\n",
    "    rownames <- row.names(eval_list[[1]])\n",
    "\n",
    "    # Convert the list back to a dataframe\n",
    "    eval_avg <- as.data.frame(eval_avg)\n",
    "\n",
    "    # Set back the row names\n",
    "    row.names(eval_avg) <- rownames\n",
    "    \n",
    "    # returns\n",
    "    results <- list(eval_avg = eval_avg,  cp_vals = cp_val)\n",
    "    return(results)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"1\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"2\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"3\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"4\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"5\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"6\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"7\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"8\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"9\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"10\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"11\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"12\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"13\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"14\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"15\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"16\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"17\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"18\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"19\"        \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " age workclass fnlwgt education marital_status occupation relationship race sex capital_gain\n",
      " capital_loss hours_per_week native_country income\n",
      "[1] 1\n",
      "[1] \"run\"       \"20\"        \"completed\"\n"
     ]
    }
   ],
   "source": [
    "adult_res <- simulation(data = adult, nrun = 10, outer_folds = 5, inner_folds = 5, mtry_steps = 10, ntree_steps = 10, cp_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] 4\n",
      "[1] \"run\"       \"1\"         \"completed\"\n",
      "\n",
      "Synthesis\n",
      "-----------\n",
      " tax income csp age educ marital race sex ss\n",
      "[1] 4\n",
      "[1] \"run\"       \"2\"         \"completed\"\n"
     ]
    }
   ],
   "source": [
    "cps_res <- simulation(data = cpspop, nrun = 10, outer_folds = 5, inner_folds = 5, mtry_steps = 10, ntree_steps = 10, cp_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in gzfile(file, mode):\n",
      "\"kann komprimierte Datei '/Users/emmafoessing/Documents/Master/MA/Code/Master-Thesis/simulation/cps_CART_res.RData' nicht \"offnen. Grund evtl. 'No such file or directory'\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in gzfile(file, mode): kann Verbindung nicht \"offnen\n",
     "output_type": "error",
     "traceback": [
      "Error in gzfile(file, mode): kann Verbindung nicht \"offnen\nTraceback:\n",
      "1. saveRDS(cps_res, file = (paste0(here(), \"/simulation/cps_CART_res.RData\")))",
      "2. gzfile(file, mode)"
     ]
    }
   ],
   "source": [
    "#Saving the data:\n",
    "saveRDS(cps_res, file = (paste0(directory, \"/simulation/cps_CART_res.RData\")))\n",
    "saveRDS(adult_res, file = (paste0(directory, \"/simulation/adult_CART_res.RData\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
